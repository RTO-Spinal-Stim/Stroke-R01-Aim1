{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "028c09e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import joblib\n",
    "import shap\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "from sklearn.utils import resample\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, f1_score\n",
    "from sklearn.utils import resample\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab027b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ML results\n",
    "\n",
    "subject_Level = False # False for Trial Level, True for Subject Level\n",
    "\n",
    "# Path To CSV file with results\n",
    "results_df = pd.read_csv(r\"Y:\\LabMembers\\Ameen\\VScode Scripts\\Spinal Stim Aim 1 Codes\\ML Results\\BRFC_preOnly_Final_10_01_25.csv\")\n",
    "\n",
    "if subject_Level:\n",
    "    # For Subject Level, keep only the trial with the highest probability away from 0.5 for each subject and outcome\n",
    "    results_df['prob_dist_from_0.5'] = (results_df['y_prob'] - 0.5).abs()\n",
    "    indices = results_df.groupby(['Subject', 'Outcome'])['prob_dist_from_0.5'].idxmax()\n",
    "    results_df = results_df.loc[indices].reset_index(drop=True)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17b45fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, f1_score\n",
    "from sklearn.utils import resample\n",
    "\n",
    "# Parameters\n",
    "PLOT_CI = True\n",
    "N_BOOTSTRAPS = 1000\n",
    "seed = 123\n",
    "rng = np.random.RandomState(seed)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(6.5, 5))\n",
    "plt.rcParams.update({\n",
    "    \"font.size\": 11,\n",
    "    \"axes.labelsize\": 12,\n",
    "    \"axes.titlesize\": 13,\n",
    "    \"legend.fontsize\": 10,\n",
    "    \"xtick.labelsize\": 11,\n",
    "    \"ytick.labelsize\": 11,\n",
    "    \"lines.linewidth\": 2,\n",
    "    \"axes.linewidth\": 1,\n",
    "    \"xtick.direction\": \"in\",\n",
    "    \"ytick.direction\": \"in\"\n",
    "})\n",
    "\n",
    "outcomes = results_df[\"Outcome\"].unique()\n",
    "fpr_grid = np.linspace(0, 1, 1000)\n",
    "colors = plt.cm.tab10.colors  # Distinct colors\n",
    "\n",
    "# Initialize before the loop\n",
    "ci_lower_f1, ci_upper_f1 = {}, {}\n",
    "\n",
    "for idx, outcome in enumerate(outcomes):\n",
    "    df_sub = results_df[results_df[\"Outcome\"] == outcome].copy()\n",
    "    if len(df_sub[\"y_true\"].unique()) < 2:\n",
    "        print(f\"Skipping ROC for '{outcome}' (only one class).\")\n",
    "        continue\n",
    "\n",
    "    # True ROC\n",
    "    fpr, tpr, _ = roc_curve(df_sub[\"y_true\"], df_sub[\"y_prob\"])\n",
    "    auc_val = roc_auc_score(df_sub[\"y_true\"], df_sub[\"y_prob\"])\n",
    "    color = colors[idx % len(colors)]\n",
    "\n",
    "    # Bootstrap arrays\n",
    "    bootstrapped_tprs = []\n",
    "    bootstrapped_auc = []\n",
    "    bootstrapped_f1 = []\n",
    "\n",
    "    # Stratified bootstrap by class\n",
    "    class_0 = df_sub[df_sub[\"y_true\"] == 0]\n",
    "    class_1 = df_sub[df_sub[\"y_true\"] == 1]\n",
    "    n_0, n_1 = len(class_0), len(class_1)\n",
    "\n",
    "    if n_0 == 0 or n_1 == 0:\n",
    "        print(f\"Skipping outcome '{outcome}' (empty class).\")\n",
    "        continue\n",
    "\n",
    "    for _ in range(N_BOOTSTRAPS):\n",
    "        sample_0 = resample(class_0, replace=True, n_samples=n_0, random_state=rng)\n",
    "        sample_1 = resample(class_1, replace=True, n_samples=n_1, random_state=rng)\n",
    "        sample = pd.concat([sample_0, sample_1], ignore_index=True)\n",
    "\n",
    "        if sample[\"y_true\"].nunique() < 2:\n",
    "            continue\n",
    "\n",
    "        # ROC + AUC\n",
    "        fpr_b, tpr_b, _ = roc_curve(sample[\"y_true\"], sample[\"y_prob\"])\n",
    "        auc_b = roc_auc_score(sample[\"y_true\"], sample[\"y_prob\"])\n",
    "        bootstrapped_auc.append(auc_b)\n",
    "\n",
    "        # Macro F1\n",
    "        f1_b = f1_score(sample[\"y_true\"], sample[\"y_pred\"], average=\"macro\", zero_division=0)\n",
    "        bootstrapped_f1.append(f1_b)\n",
    "\n",
    "        if PLOT_CI:\n",
    "            tpr_interp = np.interp(fpr_grid, fpr_b, tpr_b)\n",
    "            tpr_interp[0] = 0.0\n",
    "            tpr_interp[-1] = 1.0\n",
    "            bootstrapped_tprs.append(tpr_interp)\n",
    "\n",
    "    # Convert to arrays\n",
    "    bootstrapped_auc = np.array(bootstrapped_auc)\n",
    "    bootstrapped_f1 = np.array(bootstrapped_f1)\n",
    "\n",
    "    # Percentile CIs\n",
    "    ci_lower_auc, ci_upper_auc = np.percentile(bootstrapped_auc, [2.5, 97.5])\n",
    "    ci_lower_f1[outcome], ci_upper_f1[outcome] = np.percentile(bootstrapped_f1, [2.5, 97.5])\n",
    "\n",
    "    print(f\"\\nFor outcome '{outcome}':\")\n",
    "    print(f\"Bootstrap 95% CI for AUC:     [{ci_lower_auc:.4f}, {ci_upper_auc:.4f}]\")\n",
    "    print(f\"Bootstrap 95% CI for Macro F1:[{ci_lower_f1[outcome]:.4f}, {ci_upper_f1[outcome]:.4f}]\")\n",
    "\n",
    "    # Plot main ROC\n",
    "    plt.plot(\n",
    "        fpr, tpr,\n",
    "        label=f\"{outcome} (AUC = {auc_val:.2f}, 95% CI [{ci_lower_auc:.2f}, {ci_upper_auc:.2f}])\",\n",
    "        color=color\n",
    "    )\n",
    "\n",
    "    # Shaded CI region\n",
    "    if PLOT_CI and bootstrapped_tprs:\n",
    "        bootstrapped_tprs = np.array(bootstrapped_tprs)\n",
    "        tpr_lower = np.percentile(bootstrapped_tprs, 2.5, axis=0)\n",
    "        tpr_upper = np.percentile(bootstrapped_tprs, 97.5, axis=0)\n",
    "        plt.fill_between(\n",
    "            fpr_grid, tpr_lower, tpr_upper,\n",
    "            alpha=0.2, color=color, linewidth=0\n",
    "        )\n",
    "\n",
    "# Plot chance line\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=1, label=\"Chance\")\n",
    "\n",
    "# Labels and layout\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curves with 95% Confidence Intervals\")\n",
    "plt.legend(loc=\"lower right\", frameon=False)\n",
    "plt.grid(True, linestyle='--', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Export\n",
    "# plt.savefig(\"ROC_with_95CI.svg\", format=\"svg\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e973e07e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "from matplotlib import colors\n",
    "\n",
    "#  95% CI values\n",
    "ci_lookup = {\n",
    "    \"Frequency Label\": (ci_lower_f1['Frequency Label'], ci_upper_f1['Frequency Label']),\n",
    "    \"Intensity Label\": (ci_lower_f1['Intensity Label'], ci_upper_f1['Intensity Label'])\n",
    "}\n",
    "\n",
    "unique_outcomes = results_df['Outcome'].unique()\n",
    "n = len(unique_outcomes)\n",
    "\n",
    "fig, axes = plt.subplots(n, 1, figsize=(7, 6 * n))\n",
    "\n",
    "if n == 1:\n",
    "    axes = [axes]\n",
    "\n",
    "# Precompute confusion matrices + F1\n",
    "all_cm = []\n",
    "for outcome in unique_outcomes:\n",
    "    \n",
    "    ci_lookup = {\n",
    "    \"Frequency Label\": (0.73, 0.92),\n",
    "    \"Intensity Label\": (0.70, 0.90)\n",
    "}\n",
    "    subset = results_df[results_df['Outcome'] == outcome]\n",
    "    conf_mat = confusion_matrix(subset['y_true'], subset['y_pred'])\n",
    "    row_sums = conf_mat.sum(axis=1, keepdims=True)\n",
    "    cm_norm = conf_mat.astype('float') / row_sums\n",
    "    cm_norm = np.nan_to_num(cm_norm)\n",
    "\n",
    "    # Macro F1\n",
    "    f1 = f1_score(subset['y_true'], subset['y_pred'], average=\"macro\")\n",
    "\n",
    "    # Get CI if available\n",
    "    ci = ci_lookup.get(outcome, (np.nan, np.nan))\n",
    "\n",
    "    all_cm.append((outcome, conf_mat, row_sums, cm_norm, f1, ci))\n",
    "\n",
    "# color scale\n",
    "vmin, vmax = 0.0, 1.0\n",
    "\n",
    "# Custom orange colormap\n",
    "tab_orange = colors.LinearSegmentedColormap.from_list(\n",
    "    \"tab_orange\", [\"white\", \"#ff7f0e\"]\n",
    ")\n",
    "\n",
    "# Plot each confusion matrix\n",
    "for ax, (outcome, conf_mat, row_sums, cm_norm, f1, ci) in zip(axes, all_cm):\n",
    "    if outcome == \"Frequency Label\":\n",
    "        cmap = plt.cm.Blues\n",
    "    elif outcome == \"Intensity Label\":\n",
    "        cmap = tab_orange\n",
    "    else:\n",
    "        cmap = plt.cm.Greys\n",
    "    \n",
    "    im = ax.imshow(cm_norm, interpolation='nearest', cmap=cmap,\n",
    "                   vmin=vmin, vmax=vmax)\n",
    "    ax.set_title(f\"Confusion Matrix: {outcome}\", fontsize=16)\n",
    "    \n",
    "    tick_marks = np.arange(conf_mat.shape[0])\n",
    "    if outcome == \"Frequency Label\":\n",
    "        custom_labels = {0: \"50 Hz\", 1: \"30 Hz\"}\n",
    "    elif outcome == \"Intensity Label\":\n",
    "        custom_labels = {0: \"LOW\", 1: \"HIGH\"}\n",
    "    else:\n",
    "        custom_labels = {0: \"0\", 1: \"1\"}\n",
    "    \n",
    "    labels = [custom_labels.get(i, i) for i in tick_marks]\n",
    "    ax.set_xticks(tick_marks)\n",
    "    ax.set_xticklabels(labels, fontsize=14)\n",
    "    ax.set_yticks(tick_marks)\n",
    "    ax.set_yticklabels(labels, fontsize=14)\n",
    "    \n",
    "    # Annotate each cell\n",
    "    thresh = cm_norm.max() / 2.\n",
    "    for i in range(conf_mat.shape[0]):\n",
    "        for j in range(conf_mat.shape[1]):\n",
    "            percent = cm_norm[i, j] * 100\n",
    "            count = conf_mat[i, j]\n",
    "            denom = row_sums[i, 0] if row_sums[i, 0] > 0 else 1\n",
    "            text = f\"{percent:.1f}%\\n({count}/{denom})\"\n",
    "            ax.text(j, i, text,\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm_norm[i, j] > thresh else \"black\",\n",
    "                    fontsize=13)\n",
    "    \n",
    "    ax.set_ylabel(\"Actual\", fontsize=14)\n",
    "    ax.set_xlabel(\"Predicted\", fontsize=14)\n",
    "    \n",
    "    # --- Add Macro F1 with CI in requested format ---\n",
    "    ci_lower, ci_upper = ci\n",
    "    if not np.isnan(ci_lower):\n",
    "        text_str = f\"Macro F1: {f1:.2f}, 95% CI [{ci_lower:.2f}, {ci_upper:.2f}]\"\n",
    "    else:\n",
    "        text_str = f\"Macro F1: {f1:.2f}\"\n",
    "    \n",
    "    ax.text(\n",
    "        -0.05, -0.25, text_str,\n",
    "        ha=\"left\", va=\"center\", fontsize=14, weight=\"bold\",\n",
    "        transform=ax.transAxes,\n",
    "        bbox=dict(boxstyle=\"round,pad=0.3\", edgecolor=\"black\", facecolor=\"white\")\n",
    "    )\n",
    "\n",
    "    # Individual colorbar\n",
    "    cbar = fig.colorbar(im, ax=ax, orientation='vertical',\n",
    "                        fraction=0.046, pad=0.04)\n",
    "    cbar.ax.tick_params(labelsize=10)\n",
    "\n",
    "plt.subplots_adjust(hspace=0.5)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "925616e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_auc_score, f1_score\n",
    "\n",
    "# Load results\n",
    "results_file = r\"C:\\Users\\akishta03\\Documents\\SS_ML\\ML Results\\EasyEnsemble_preOnly_20250908_Final_LearningCurve.csv\"\n",
    "df = pd.read_csv(results_file)\n",
    "\n",
    "# Learning Curve Plot \n",
    "outcomes = df[\"Outcome\"].unique()\n",
    "metrics = [\"AUC\", \"Macro F1\"]\n",
    "\n",
    "fig, axes = plt.subplots(1, len(outcomes), figsize=(6 * len(outcomes), 5), sharey=True)\n",
    "\n",
    "if len(outcomes) == 1:\n",
    "    axes = [axes]  # make iterable\n",
    "\n",
    "for ax, outcome in zip(axes, outcomes):\n",
    "    df_out = df[df[\"Outcome\"] == outcome]\n",
    "\n",
    "    # Collect metrics per repeat Ã— subjects\n",
    "    records = []\n",
    "    for (num_subj, rep), g in df_out.groupby([\"Num_Subjects\", \"Repeat\"]):\n",
    "        try:\n",
    "            auc = roc_auc_score(g[\"y_true\"], g[\"y_prob\"])\n",
    "        except ValueError:\n",
    "            auc = np.nan\n",
    "        f1 = f1_score(g[\"y_true\"], g[\"y_pred\"], average=\"macro\", zero_division=0)\n",
    "        records.append({\"Num_Subjects\": num_subj, \"Repeat\": rep, \"AUC\": auc, \"Macro F1\": f1})\n",
    "    \n",
    "    df_scores = pd.DataFrame(records)\n",
    "\n",
    "    # Average across repeats (no std)\n",
    "    avg_scores = df_scores.groupby(\"Num_Subjects\").mean().reset_index()\n",
    "\n",
    "    # Plot AUC and F1\n",
    "    for metric, color in zip(metrics, [\"blue\", \"green\"]):\n",
    "        x_vals = avg_scores[\"Num_Subjects\"]\n",
    "        y_vals = avg_scores[metric]\n",
    "        ax.plot(x_vals, y_vals, marker=\"o\", color=color, label=metric)\n",
    "\n",
    "    ax.set_title(f\"Learning Curve: {outcome}\", fontsize=13)\n",
    "    ax.set_xlabel(\"Number of Subjects\", fontsize=12)\n",
    "    ax.set_ylabel(\"Score\", fontsize=12)\n",
    "    ax.legend()\n",
    "    ax.grid(True, linestyle=\"--\", alpha=0.5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MAIN_ENV (3.12.6)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
